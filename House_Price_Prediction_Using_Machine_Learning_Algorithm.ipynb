{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRbsZltGcAbM"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnwpEvJbt1Qs"
      },
      "outputs": [],
      "source": [
        "#Connecting Google Drive or else download the dataset and access through files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBx1CYEwPQkY"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1ixrLsnPQy7"
      },
      "outputs": [],
      "source": [
        "#Reading data\n",
        "data = pd.read_csv('/content/drive/MyDrive/IOMP/Hyderabad-Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piH9SXK7vWNM"
      },
      "outputs": [],
      "source": [
        " data = data.sample(n=2000,random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyDqzE7PvWTp"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0YDrTbjvWWw"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SFjsMqmvWZp"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPvyAspYvWcv"
      },
      "outputs": [],
      "source": [
        "#Dropping Irrelevant columns\n",
        "New_Data = data.drop(['active', 'amenities', 'balconies',\n",
        "       'completeStreetName', 'facing', 'facingDesc',\n",
        "        'id', 'isMaintenance', 'lift', 'loanAvailable',\n",
        "         'ownerName','waterSupply',\n",
        "       'reactivationSource',\n",
        "        'shortUrl', 'swimmingPool',\n",
        "        'weight','combineDescription','deposit','furnishingDesc','gym','parking','parkingDesc',\n",
        "                      'location','localityId','propertyTitle','propertyType','sharedAccomodation']\n",
        ",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmGmlZf_vWfw"
      },
      "outputs": [],
      "source": [
        "# after removing irrelevant columns\n",
        "New_Data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hquRpFbSvWia"
      },
      "outputs": [],
      "source": [
        "New_Data.replace({'type_bhk':{'RK1':0.5,'BHK1':1,'BHK2':2,'BHK3':3,'BHK4':4,'BHK4PLUS':5}},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7dXt-g6J1n3"
      },
      "outputs": [],
      "source": [
        "# Replace 'None' with 0 in the 'maintenanceAmount' and 'rent_amount' columns\n",
        "New_Data['maintenanceAmount'].replace('None', 0, inplace=True)\n",
        "New_Data['rent_amount'].replace('None', 0, inplace=True)\n",
        "\n",
        "# Convert the 'maintenanceAmount' and 'rent_amount' columns to numeric data\n",
        "New_Data['maintenanceAmount'] = pd.to_numeric(New_Data['maintenanceAmount'])\n",
        "New_Data['rent_amount'] = pd.to_numeric(New_Data['rent_amount'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh5qzMyVvWlQ"
      },
      "outputs": [],
      "source": [
        "# Assuming 'object_column' contains strings and 'int_column' contains integ\n",
        "New_Data['total_price'] = New_Data['maintenanceAmount'].astype(str) + New_Data['rent_amount'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9F-33vBvWoP"
      },
      "outputs": [],
      "source": [
        "New_Data['total_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_ltFLIHvWp6"
      },
      "outputs": [],
      "source": [
        "#Concatenating\n",
        "New_Data = pd.concat([New_Data.iloc[:, :-1], New_Data['total_price']], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIxFSk12wIdF"
      },
      "outputs": [],
      "source": [
        "New_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1p9X3bKwIgL"
      },
      "outputs": [],
      "source": [
        "New_Data = New_Data.drop(['rent_amount', 'maintenanceAmount'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga6kwTHAwIjj"
      },
      "outputs": [],
      "source": [
        "New_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J-2EnhzwIme"
      },
      "outputs": [],
      "source": [
        "# after removing irrelevant columns\n",
        "New_Data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDIvjSqewIsP"
      },
      "outputs": [],
      "source": [
        "New_Data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUPeyccbwIu3"
      },
      "outputs": [],
      "source": [
        "New_Data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6_kd0i8wIxj"
      },
      "outputs": [],
      "source": [
        "New_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_ob1wRy0b1V"
      },
      "outputs": [],
      "source": [
        "New_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vi2S7b-97PFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OUTLIERS ANALYSIS\n"
      ],
      "metadata": {
        "id": "1LB4LMKJ7R1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdv6ky2t7t-Y"
      },
      "outputs": [],
      "source": [
        "#Function() to detect Outliers\n",
        "def detect_outliers_z_score(New_Data):\n",
        "    threshold = 3\n",
        "    mean = New_Data.mean()\n",
        "    std = New_Data.std()\n",
        "    z_scores = (New_Data - mean) / std\n",
        "    return (z_scores > threshold) | (z_scores < -threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6APjmgvg5-"
      },
      "outputs": [],
      "source": [
        "# Outliers in property_size\n",
        "outliers= detect_outliers_z_score(New_Data['property_size'])\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in the column:\")\n",
        "    print(outliers)\n",
        "#property_size\n",
        "#property_age\n",
        "#totalFloor\n",
        "#type_bhk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roGAkcsivnw8"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(New_Data['property_size'])\n",
        "plt.title('Boxplot for type_bhk')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQAeNKLAvutv"
      },
      "outputs": [],
      "source": [
        "Data = New_Data[~New_Data['property_size'].isin(outliers)]\n",
        "\n",
        "# Print the DataFrame after removing outliers\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uozDI6JBG7g8"
      },
      "outputs": [],
      "source": [
        "# Outliers in property_age\n",
        "outliers= detect_outliers_z_score(New_Data['property_age'])\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in the column:\")\n",
        "    print(outliers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmbf4173G7a2"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(New_Data['property_age'])\n",
        "plt.title('Boxplot for type_bhk')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUsv8cSbHEso"
      },
      "outputs": [],
      "source": [
        "Data = New_Data[~New_Data['property_age'].isin(outliers)]\n",
        "\n",
        "# Print the DataFrame after removing outliers\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqVnMJ8sHJHw"
      },
      "outputs": [],
      "source": [
        "# Outliers in totalFloor\n",
        "outliers= detect_outliers_z_score(New_Data['totalFloor'])\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in the column:\")\n",
        "    print(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aD_blcEHJFM"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(New_Data['totalFloor'])\n",
        "plt.title('Boxplot for type_bhk')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9X96B0WHJCL"
      },
      "outputs": [],
      "source": [
        "Data = New_Data[~New_Data['totalFloor'].isin(outliers)]\n",
        "\n",
        "# Print the DataFrame after removing outliers\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfJqypLlHWp9"
      },
      "outputs": [],
      "source": [
        "# Outliers in type_bhk\n",
        "outliers= detect_outliers_z_score(New_Data['type_bhk'])\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in the column:\")\n",
        "    print(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ETevA8PHWnk"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(New_Data['type_bhk'])\n",
        "plt.title('Boxplot for type_bhk')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY6fzOJ9HWlJ"
      },
      "outputs": [],
      "source": [
        "Data = New_Data[~New_Data['type_bhk'].isin(outliers)]\n",
        "\n",
        "# Print the DataFrame after removing outliers\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw_FRmHzHt7y"
      },
      "outputs": [],
      "source": [
        "# Outliers in bathroom\n",
        "outliers= detect_outliers_z_score(New_Data['bathroom'])\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in the column:\")\n",
        "    print(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QRaAlUwHt5K"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(New_Data['bathroom'])\n",
        "plt.title('Boxplot for type_bhk')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq4myCDDHt2Z"
      },
      "outputs": [],
      "source": [
        "Data = New_Data[~New_Data['bathroom'].isin(outliers)]\n",
        "\n",
        "# Print the DataFrame after removing outliers\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lc5sqvg10qD"
      },
      "outputs": [],
      "source": [
        "locality_data = New_Data['locality']\n",
        "print(locality_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rdMJJYiIkdm"
      },
      "outputs": [],
      "source": [
        "New_Data = Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fqxfUHbEPN2"
      },
      "outputs": [],
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'locality' column\n",
        "New_Data['locality_encoded'] = label_encoder.fit_transform(New_Data['locality'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpHgZQKHED5M"
      },
      "outputs": [],
      "source": [
        "# Features and target variable\n",
        "X = New_Data[['bathroom','locality_encoded', 'property_age', 'property_size', 'totalFloor', 'type_bhk']]\n",
        "y = New_Data['total_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFPXgUvdEJSz"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZofYSgMERuK"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGNjW-L9K_RV"
      },
      "outputs": [],
      "source": [
        "New_Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ZK6CiKd97ofZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "D01b_Zst7qdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKqm8_Sj10yw"
      },
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "#Just fuckin increase the accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfQjBPNj102P"
      },
      "outputs": [],
      "source": [
        "\n",
        "# User input\n",
        "user_inputs = {}\n",
        "\n",
        "# user_inputs['floor'] = int(input(\"Enter the floor number: \"))\n",
        "user_inputs['locality'] = input(\"Enter the locality: \")\n",
        "user_inputs['property_age'] = int(input(\"Enter the property age: \"))\n",
        "user_inputs['property_size'] = int(input(\"Enter the property size: \"))\n",
        "user_inputs['totalFloor'] = int(input(\"Enter the total floor: \"))\n",
        "user_inputs['type_bhk'] = float(input(\"Enter the type BHK: \"))\n",
        "user_inputs['bathroom'] = int(input(\"Enter the number of bathrooms: \"))\n",
        "\n",
        "# Convert user input to DataFrame\n",
        "input_df = pd.DataFrame([user_inputs])\n",
        "\n",
        "# Encode the 'locality' column\n",
        "input_df['locality_encoded'] = label_encoder.transform(input_df['locality'])\n",
        "\n",
        "# Make predictions\n",
        "predicted_prices = model.predict(input_df[['bathroom','locality_encoded', 'property_age', 'property_size', 'totalFloor', 'type_bhk']])\n",
        "\n",
        "# Display the predicted total price\n",
        "print(f\"The predicted total price is: {predicted_prices[0]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zNq8_C9Pw4s"
      },
      "outputs": [],
      "source": [
        "if 'Narapally' in New_Data['locality'].values:\n",
        "    print(\"narapally is present in the 'locality' column.\")\n",
        "else:\n",
        "    print(\"narapally is not present in the 'locality' column.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X9yhzSXurDB"
      },
      "source": [
        "Below codes are experiments for other models u can try if u want to :>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnK88pJguoPr"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define the parameter grid for Gradient Boosting Regressor\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2],\n",
        "#     'max_depth': [3, 4, 5]\n",
        "# }\n",
        "\n",
        "# # Initialize the Gradient Boosting Regressor\n",
        "# gb_regressor = GradientBoostingRegressor()\n",
        "\n",
        "# # Initialize GridSearchCV\n",
        "# grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best hyperparameters\n",
        "# best_params = grid_search.best_params_\n",
        "\n",
        "# # Use the best hyperparameters to train the model\n",
        "# best_model = GradientBoostingRegressor(**best_params)\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = best_model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# print(f'Mean Squared Error on Test Set: {mse}')\n",
        "\n",
        "# # Display the best hyperparameters\n",
        "# print('Best Hyperparameters:', best_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.ensemble import GradientBoostingRegressor\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# # Define the parameter grid for Gradient Boosting Regressor\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2],\n",
        "#     'max_depth': [3, 4, 5],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 5],\n",
        "#     'max_features': [None, 'auto', 'sqrt']\n",
        "# }\n",
        "\n",
        "# # Initialize the Gradient Boosting Regressor\n",
        "# gb_regressor = GradientBoostingRegressor()\n",
        "\n",
        "# # Initialize GridSearchCV\n",
        "# grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, scoring='r2', cv=10)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best hyperparameters\n",
        "# best_params = grid_search.best_params_\n",
        "\n",
        "# # Use the best hyperparameters to train the model\n",
        "# best_model = GradientBoostingRegressor(**best_params)\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = best_model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# print(f'Mean Squared Error on Test Set: {mse}')\n",
        "\n",
        "# # Display the best hyperparameters\n",
        "# print('Best Hyperparameters:', best_params)\n"
      ],
      "metadata": {
        "id": "grBRbvCzHPay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P77a6Bt1I0b"
      },
      "outputs": [],
      "source": [
        "# # import pandas as pd\n",
        "# # from sklearn.model_selection import train_test_split\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# # from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# # Assuming 'total_price' is your target variable\n",
        "# # X = New_Data.drop('total_price', axis=1)\n",
        "# # y = New_Data['total_price']\n",
        "\n",
        "# # # Split the data into training and testing sets\n",
        "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Create a Decision Tree Regressor model\n",
        "# model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# predictions = model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# mae = mean_absolute_error(y_test, predictions)\n",
        "# mse = mean_squared_error(y_test, predictions)\n",
        "# rmse = (mse)**0.5\n",
        "# r2 = r2_score(y_test, predictions)\n",
        "\n",
        "# print(f\"Mean Absolute Error: {mae}\")\n",
        "# print(f\"Mean Squared Error: {mse}\")\n",
        "# print(f\"Root Mean Squared Error: {rmse}\")\n",
        "# print(f\"R-squared: {r2}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}